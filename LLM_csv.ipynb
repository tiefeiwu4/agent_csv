{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428df855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择模型\n",
    "import os \n",
    "os.environ['OPENAI_API_KEY'] = 'sk-H44EbzZSAeJFexZH7ur6X6tbvsLoeAxPVSjE47WakODjXuEF' # 导入的api key\n",
    "os.environ['OPENAI_API_BASE'] = 'https://api.34ku.com/v1'  # 一定要有 /v1\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\",temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "class GlobalState:\n",
    "    df: Optional[pd.DataFrame] = None\n",
    "    models = {}  # model_id \n",
    "\n",
    "STATE = GlobalState()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511948b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义工具(tools)\n",
    "import io\n",
    "import json\n",
    "import uuid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1) 载入 CSV\n",
    "class LoadCSVInput(BaseModel):\n",
    "    path: str = Field(..., description=\"本地 CSV 文件路径，比如 './titanic_cleaned.csv'\")\n",
    "\n",
    "def load_csv_tool(path: str) -> Dict[str, Any]:\n",
    "    df = pd.read_csv(path)\n",
    "    STATE.df = df\n",
    "    return {\"rows\": len(df), \"columns\": list(df.columns)}\n",
    "\n",
    "load_csv = StructuredTool.from_function(\n",
    "    func=load_csv_tool,\n",
    "    name=\"load_csv\",\n",
    "    description=\"加载一个CSV文件到内存，后续所有操作都基于此数据集。\",\n",
    "    args_schema=LoadCSVInput\n",
    ")\n",
    "\n",
    "# 2) 数据 summary（均值、方差、极值等，仅数值列）\n",
    "class SummaryInput(BaseModel):\n",
    "    columns: Optional[List[str]] = Field(None, description=\"要统计的列名列表，空则使用所有数值列\")\n",
    "\n",
    "def data_summary_tool(columns: Optional[List[str]] = None) -> Dict[str, Any]:\n",
    "    assert STATE.df is not None, \"请先用 load_csv 加载数据\"\n",
    "    df = STATE.df\n",
    "    num_df = df.select_dtypes(include=[np.number])\n",
    "    if columns:\n",
    "        num_df = num_df[columns]\n",
    "    desc = num_df.agg([\"mean\", \"var\", \"min\", \"max\"]).to_dict()\n",
    "    return {\"summary\": desc}\n",
    "\n",
    "data_summary = StructuredTool.from_function(\n",
    "    func=data_summary_tool,\n",
    "    name=\"data_summary\",\n",
    "    description=\"对数值列做统计汇总：mean/var/min/max。\",\n",
    "    args_schema=SummaryInput\n",
    ")\n",
    "\n",
    "# 3) 缺失值均值填充（只对数值列；可指定列）\n",
    "class ImputeMeanInput(BaseModel):\n",
    "    columns: Optional[List[str]] = Field(None, description=\"要填充的数值列，空则为所有数值列\")\n",
    "\n",
    "def impute_mean_tool(columns: Optional[List[str]] = None) -> Dict[str, Any]:\n",
    "    assert STATE.df is not None, \"请先用 load_csv 加载数据\"\n",
    "    df = STATE.df\n",
    "    num_cols = list(df.select_dtypes(include=[np.number]).columns)\n",
    "    target_cols = columns or num_cols\n",
    "    before_na = df[target_cols].isna().sum().sum()\n",
    "    for c in target_cols:\n",
    "        if c in df.columns and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            df[c] = df[c].fillna(df[c].mean())\n",
    "    after_na = df[target_cols].isna().sum().sum()\n",
    "    imputed = int(before_na - after_na)\n",
    "    STATE.df = df\n",
    "    return {\"updated_columns\": target_cols, \"n_imputed\": imputed}\n",
    "\n",
    "impute_mean = StructuredTool.from_function(\n",
    "    func=impute_mean_tool,\n",
    "    name=\"impute_mean\",\n",
    "    description=\"将数值列中的缺失值用该列均值进行填充。\",\n",
    "    args_schema=ImputeMeanInput\n",
    ")\n",
    "\n",
    "# 4) 画分布图（默认 Survived），保存为PNG并返回路径\n",
    "class PlotDistInput(BaseModel):\n",
    "    column: str = Field(\"Survived\", description=\"要绘制分布的列名\")\n",
    "    bins: int = Field(20, description=\"直方图箱数，类别变量自动用条形图\")\n",
    "\n",
    "def plot_distribution_tool(column: str = \"Survived\", bins: int = 20) -> Dict[str, Any]:\n",
    "    assert STATE.df is not None, \"请先用 load_csv 加载数据\"\n",
    "    df = STATE.df\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"列 {column} 不在数据中\")\n",
    "    path = f\"plot_{column}.png\"\n",
    "\n",
    "    plt.figure()\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        df[column].plot(kind=\"hist\", bins=bins, edgecolor=\"black\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "    else:\n",
    "        df[column].value_counts().plot(kind=\"bar\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    return {\"image_path\": path}\n",
    "\n",
    "plot_distribution = StructuredTool.from_function(\n",
    "    func=plot_distribution_tool,\n",
    "    name=\"plot_distribution\",\n",
    "    description=\"绘制某一列的分布图，数值列用直方图，类别列用条形图。将图片保存为本地PNG并返回路径。\",\n",
    "    args_schema=PlotDistInput\n",
    ")\n",
    "\n",
    "# 5) 训练模型 + 评估（默认逻辑回归预测 Survived）\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "class TrainModelInput(BaseModel):\n",
    "    target: str = Field(\"Survived\", description=\"目标列名\")\n",
    "    features: Optional[List[str]] = Field(None, description=\"特征列列表，空则自动选择除目标外的所有列\")\n",
    "    model_type: str = Field(\"logreg\", description=\"模型类型。目前支持 logreg\")\n",
    "    test_size: float = Field(0.2, description=\"测试集比例\")\n",
    "    random_state: int = Field(42, description=\"随机种子\")\n",
    "\n",
    "def train_model_tool(\n",
    "    target: str = \"Survived\",\n",
    "    features: Optional[List[str]] = None,\n",
    "    model_type: str = \"logreg\",\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    ") -> Dict[str, Any]:\n",
    "    assert STATE.df is not None, \"请先用 load_csv 加载数据\"\n",
    "    df = STATE.df.copy()\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"目标列 {target} 不在数据中\")\n",
    "\n",
    "    X = df.drop(columns=[target]) if features is None else df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    # 自动区分数值/类别列\n",
    "    num_cols = list(X.select_dtypes(include=[np.number]).columns)\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    if model_type == \"logreg\":\n",
    "        model = LogisticRegression(max_iter=200)\n",
    "    else:\n",
    "        raise ValueError(\"暂只支持 logreg\")\n",
    "\n",
    "    pipe = Pipeline(steps=[(\"pre\", pre), (\"clf\", model)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y if y.nunique() <= 20 else None\n",
    "    )\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"f1\": float(f1_score(y_test, y_pred, average=\"weighted\")),\n",
    "    }\n",
    "    # 二分类可给出 ROC-AUC（需要概率 & 目标二值）\n",
    "    try:\n",
    "        if y.nunique() == 2 and hasattr(pipe, \"predict_proba\"):\n",
    "            y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "            metrics[\"roc_auc\"] = float(roc_auc_score(y_test, y_proba))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
    "    model_id = str(uuid.uuid4())[:8]\n",
    "    STATE.models[model_id] = pipe\n",
    "\n",
    "    return {\"model_id\": model_id, \"metrics\": metrics, \"confusion_matrix\": cm}\n",
    "\n",
    "train_model = StructuredTool.from_function(\n",
    "    func=train_model_tool,\n",
    "    name=\"train_model\",\n",
    "    description=\"训练一个用于分类的模型（默认逻辑回归）并返回评估指标与 model_id。\",\n",
    "    args_schema=TrainModelInput\n",
    ")\n",
    "\n",
    "# 6) 预测（预览前 N 条）\n",
    "class PredictInput(BaseModel):\n",
    "    model_id: str = Field(..., description=\"训练时返回的 model_id\")\n",
    "    head: int = Field(10, description=\"返回前 N 条预测\")\n",
    "\n",
    "def predict_tool(model_id: str, head: int = 10) -> Dict[str, Any]:\n",
    "    assert STATE.df is not None, \"请先用 load_csv 加载数据\"\n",
    "    if model_id not in STATE.models:\n",
    "        raise ValueError(f\"找不到模型 {model_id}\")\n",
    "    model = STATE.models[model_id]\n",
    "\n",
    "    # 使用整表的前 head 行进行演示（真实场景可传入自定义数据）\n",
    "    X = STATE.df.drop(columns=[c for c in [\"Survived\"] if c in STATE.df.columns]).head(head)\n",
    "    preds = model.predict(X).tolist()\n",
    "    out = X.copy()\n",
    "    out[\"pred\"] = preds\n",
    "    return {\"preview\": out.to_dict(orient=\"records\")}\n",
    "\n",
    "predict = StructuredTool.from_function(\n",
    "    func=predict_tool,\n",
    "    name=\"predict\",\n",
    "    description=\"使用已训练的模型进行预测，返回前N条样例的预测结果。\",\n",
    "    args_schema=PredictInput\n",
    ")\n",
    "\n",
    "TOOLS = [load_csv, data_summary, impute_mean, plot_distribution, train_model, predict]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30897fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建agent\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_core.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class PrintCallback(BaseCallbackHandler):\n",
    "    def on_chain_start(self, *args, **kwargs):\n",
    "        print(\"=== Chain start ===\")\n",
    "\n",
    "    def on_tool_start(self, serialized, input_str, **kwargs):\n",
    "        print(f\"[Tool start] {serialized.get('name')}  input={input_str}\")\n",
    "\n",
    "    def on_tool_end(self, output, **kwargs):\n",
    "        print(f\"[Tool end]   output={str(output)[:300]} ...\")\n",
    "\n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        print(\"=== Chain end ===\")\n",
    "\n",
    "callbacks = [PrintCallback()]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a data-exploration assistant. \"\n",
    "    \"You MUST use the provided tools to load data, summarize, impute, plot, train and predict. \"\n",
    "    \"If the user request is ambiguous, ask for clarification or make sensible defaults and state them.\"\n",
    ")\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=TOOLS,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,  \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    agent_kwargs={\"system_message\": system_prompt},\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3805a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain start ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to load the CSV file to check the number of rows and the column names. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"load_csv\",\n",
      "  \"action_input\": {\n",
      "    \"path\": \"./titanic_cleaned.csv\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'rows': 891, 'columns': ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully loaded the CSV file and obtained the required information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The dataset contains 891 rows and the following columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'].\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "=== Chain end ===\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The dataset contains 891 rows and the following columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'].\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"用工具把 ./titanic_cleaned.csv 加载进来，并告诉我有多少行，以及所有列名。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2e5740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain start ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to load the CSV file first to access the numerical columns for statistical summary. I will ask for the file path to proceed.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"load_csv\",\n",
      "  \"action_input\": {\n",
      "    \"path\": \"./titanic_cleaned.csv\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'rows': 891, 'columns': ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully loaded the CSV file and can now access the numerical columns for statistical summary. I will proceed to generate the summary statistics including mean, variance, minimum, and maximum for all numerical columns.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"data_summary\",\n",
      "  \"action_input\": {\n",
      "    \"columns\": null\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'summary': {'PassengerId': {'mean': 446.0, 'var': 66231.0, 'min': 1.0, 'max': 891.0}, 'Survived': {'mean': 0.3838383838383838, 'var': 0.23677221654749742, 'min': 0.0, 'max': 1.0}, 'Pclass': {'mean': 2.308641975308642, 'var': 0.6990151199889028, 'min': 1.0, 'max': 3.0}, 'Age': {'mean': 29.69911764705882, 'var': 169.0523999372108, 'min': 0.42, 'max': 80.0}, 'SibSp': {'mean': 0.5230078563411896, 'var': 1.2160430774662985, 'min': 0.0, 'max': 8.0}, 'Parch': {'mean': 0.38159371492704824, 'var': 0.6497282437357343, 'min': 0.0, 'max': 6.0}, 'Fare': {'mean': 32.204207968574636, 'var': 2469.436845743116, 'min': 0.0, 'max': 512.3292}}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully generated the statistical summary for the numerical columns, which includes the mean, variance, minimum, and maximum values. Here are the results:\n",
      "\n",
      "- **PassengerId**: \n",
      "  - Mean: 446.0\n",
      "  - Variance: 66231.0\n",
      "  - Min: 1.0\n",
      "  - Max: 891.0\n",
      "\n",
      "- **Survived**: \n",
      "  - Mean: 0.384\n",
      "  - Variance: 0.237\n",
      "  - Min: 0.0\n",
      "  - Max: 1.0\n",
      "\n",
      "- **Pclass**: \n",
      "  - Mean: 2.309\n",
      "  - Variance: 0.699\n",
      "  - Min: 1.0\n",
      "  - Max: 3.0\n",
      "\n",
      "- **Age**: \n",
      "  - Mean: 29.699\n",
      "  - Variance: 169.052\n",
      "  - Min: 0.42\n",
      "  - Max: 80.0\n",
      "\n",
      "- **SibSp**: \n",
      "  - Mean: 0.523\n",
      "  - Variance: 1.216\n",
      "  - Min: 0.0\n",
      "  - Max: 8.0\n",
      "\n",
      "- **Parch**: \n",
      "  - Mean: 0.382\n",
      "  - Variance: 0.650\n",
      "  - Min: 0.0\n",
      "  - Max: 6.0\n",
      "\n",
      "- **Fare**: \n",
      "  - Mean: 32.204\n",
      "  - Variance: 2469.437\n",
      "  - Min: 0.0\n",
      "  - Max: 512.329\n",
      "\n",
      "If you need any further analysis or information, feel free to ask!\u001b[0m\n",
      "=== Chain end ===\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have successfully generated the statistical summary for the numerical columns, which includes the mean, variance, minimum, and maximum values. Here are the results:\\n\\n- **PassengerId**: \\n  - Mean: 446.0\\n  - Variance: 66231.0\\n  - Min: 1.0\\n  - Max: 891.0\\n\\n- **Survived**: \\n  - Mean: 0.384\\n  - Variance: 0.237\\n  - Min: 0.0\\n  - Max: 1.0\\n\\n- **Pclass**: \\n  - Mean: 2.309\\n  - Variance: 0.699\\n  - Min: 1.0\\n  - Max: 3.0\\n\\n- **Age**: \\n  - Mean: 29.699\\n  - Variance: 169.052\\n  - Min: 0.42\\n  - Max: 80.0\\n\\n- **SibSp**: \\n  - Mean: 0.523\\n  - Variance: 1.216\\n  - Min: 0.0\\n  - Max: 8.0\\n\\n- **Parch**: \\n  - Mean: 0.382\\n  - Variance: 0.650\\n  - Min: 0.0\\n  - Max: 6.0\\n\\n- **Fare**: \\n  - Mean: 32.204\\n  - Variance: 2469.437\\n  - Min: 0.0\\n  - Max: 512.329\\n\\nIf you need any further analysis or information, feel free to ask!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"请给出数值列的统计汇总，包括均值、方差、最小值和最大值。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5eba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain start ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to plot the distribution of the \"Survived\" column and save the image, then provide the path to the saved image. First, I will load the dataset to access the \"Survived\" column.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"load_csv\",\n",
      "  \"action_input\": {\n",
      "    \"path\": \"./titanic_cleaned.csv\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'rows': 891, 'columns': ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully loaded the dataset and can now plot the distribution of the \"Survived\" column.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"plot_distribution\",\n",
      "  \"action_input\": {\n",
      "    \"column\": \"Survived\",\n",
      "    \"bins\": 20\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'image_path': 'plot_Survived.png'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have plotted the distribution of the \"Survived\" column and saved the image. The image is saved at the following path:\n",
      "\n",
      "\u001b[0m\n",
      "=== Chain end ===\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have plotted the distribution of the \"Survived\" column and saved the image. The image is saved at the following path:\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"画一下 Survived 的分布图，并告诉我图片的保存路径。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be85904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain start ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 首先，我需要加载数据集，然后训练一个逻辑回归模型来预测 \"Survived\"。在训练模型时，我将使用默认的特征列和测试集比例。训练完成后，我将获取模型的评估指标，包括准确率、F1 分数和 ROC-AUC（如果可用）。接下来，我将返回 model_id。\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"load_csv\",\n",
      "  \"action_input\": {\n",
      "    \"path\": \"./titanic_cleaned.csv\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'rows': 891, 'columns': ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我已经成功加载了数据集。接下来，我将训练一个逻辑回归模型来预测 \"Survived\"，并获取模型的评估指标。\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"train_model\",\n",
      "  \"action_input\": {\n",
      "    \"target\": \"Survived\",\n",
      "    \"features\": null,\n",
      "    \"model_type\": \"logreg\",\n",
      "    \"test_size\": 0.2,\n",
      "    \"random_state\": 42\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'model_id': 'a313126e', 'metrics': {'accuracy': 0.8268156424581006, 'f1': 0.8248588228685629, 'roc_auc': 0.8545454545454545}, 'confusion_matrix': [[98, 12], [19, 50]]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我已经成功训练了逻辑回归模型，并获得了评估指标。模型的准确率为 0.827，F1 分数为 0.825，ROC-AUC 为 0.855。模型的 ID 是 'a313126e'。\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"模型的准确率为 0.827，F1 分数为 0.825，ROC-AUC 为 0.855，模型 ID 是 'a313126e'。\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "=== Chain end ===\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "模型的准确率为 0.827，F1 分数为 0.825，ROC-AUC 为 0.855，模型 ID 是 'a313126e'。\n"
     ]
    }
   ],
   "source": [
    "resp = agent.run(\"用逻辑回归训练一个预测 Survived 的模型，给出准确率、F1、如可用再给 ROC-AUC，并返回 model_id。\")\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67331727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain start ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"predict\",\n",
      "  \"action_input\": {\n",
      "    \"model_id\": \"a313126e\",\n",
      "    \"head\": 10\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'preview': [{'PassengerId': 1, 'Pclass': 3, 'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': 22.0, 'SibSp': 1, 'Parch': 0, 'Ticket': 'A/5 21171', 'Fare': 7.25, 'Cabin': 'C92', 'Embarked': 'S', 'pred': 0}, {'PassengerId': 2, 'Pclass': 1, 'Name': 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Sex': 'female', 'Age': 38.0, 'SibSp': 1, 'Parch': 0, 'Ticket': 'PC 17599', 'Fare': 71.2833, 'Cabin': 'C85', 'Embarked': 'C', 'pred': 1}, {'PassengerId': 3, 'Pclass': 3, 'Name': 'Heikkinen, Miss. Laina', 'Sex': 'female', 'Age': 26.0, 'SibSp': 0, 'Parch': 0, 'Ticket': 'STON/O2. 3101282', 'Fare': 7.925, 'Cabin': 'C92', 'Embarked': 'S', 'pred': 1}, {'PassengerId': 4, 'Pclass': 1, 'Name': 'Futrelle, Mrs. Jacques Heath (Lily May Peel)', 'Sex': 'female', 'Age': 35.0, 'SibSp': 1, 'Parch': 0, 'Ticket': '113803', 'Fare': 53.1, 'Cabin': 'C123', 'Embarked': 'S', 'pred': 1}, {'PassengerId': 5, 'Pclass': 3, 'Name': 'Allen, Mr. William Henry', 'Sex': 'male', 'Age': 35.0, 'SibSp': 0, 'Parch': 0, 'Ticket': '373450', 'Fare': 8.05, 'Cabin': 'C92', 'Embarked': 'S', 'pred': 0}, {'PassengerId': 6, 'Pclass': 3, 'Name': 'Moran, Mr. James', 'Sex': 'male', 'Age': 29.69911764705882, 'SibSp': 0, 'Parch': 0, 'Ticket': '330877', 'Fare': 8.4583, 'Cabin': 'C92', 'Embarked': 'Q', 'pred': 0}, {'PassengerId': 7, 'Pclass': 1, 'Name': 'McCarthy, Mr. Timothy J', 'Sex': 'male', 'Age': 54.0, 'SibSp': 0, 'Parch': 0, 'Ticket': '17463', 'Fare': 51.8625, 'Cabin': 'E46', 'Embarked': 'S', 'pred': 0}, {'PassengerId': 8, 'Pclass': 3, 'Name': 'Palsson, Master. Gosta Leonard', 'Sex': 'male', 'Age': 2.0, 'SibSp': 3, 'Parch': 1, 'Ticket': '349909', 'Fare': 21.075, 'Cabin': 'C92', 'Embarked': 'S', 'pred': 0}, {'PassengerId': 9, 'Pclass': 3, 'Name': 'Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)', 'Sex': 'female', 'Age': 27.0, 'SibSp': 0, 'Parch': 2, 'Ticket': '347742', 'Fare': 11.1333, 'Cabin': 'C92', 'Embarked': 'S', 'pred': 1}, {'PassengerId': 10, 'Pclass': 2, 'Name': 'Nasser, Mrs. Nicholas (Adele Achem)', 'Sex': 'female', 'Age': 14.0, 'SibSp': 1, 'Parch': 0, 'Ticket': '237736', 'Fare': 30.0708, 'Cabin': 'C92', 'Embarked': 'C', 'pred': 1}]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully used the trained model with model_id \"a313126e\" to make predictions. Here are the predictions for the first 10 samples:\n",
      "\n",
      "1. **PassengerId**: 1, **Predicted Survival**: 0\n",
      "2. **PassengerId**: 2, **Predicted Survival**: 1\n",
      "3. **PassengerId**: 3, **Predicted Survival**: 1\n",
      "4. **PassengerId**: 4, **Predicted Survival**: 1\n",
      "5. **PassengerId**: 5, **Predicted Survival**: 0\n",
      "6. **PassengerId**: 6, **Predicted Survival**: 0\n",
      "7. **PassengerId**: 7, **Predicted Survival**: 0\n",
      "8. **PassengerId**: 8, **Predicted Survival**: 0\n",
      "9. **PassengerId**: 9, **Predicted Survival**: 1\n",
      "10. **PassengerId**: 10, **Predicted Survival**: 1\n",
      "\n",
      "If you need further analysis or details, feel free to ask!\u001b[0m\n",
      "=== Chain end ===\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have successfully used the trained model with model_id \"a313126e\" to make predictions. Here are the predictions for the first 10 samples:\\n\\n1. **PassengerId**: 1, **Predicted Survival**: 0\\n2. **PassengerId**: 2, **Predicted Survival**: 1\\n3. **PassengerId**: 3, **Predicted Survival**: 1\\n4. **PassengerId**: 4, **Predicted Survival**: 1\\n5. **PassengerId**: 5, **Predicted Survival**: 0\\n6. **PassengerId**: 6, **Predicted Survival**: 0\\n7. **PassengerId**: 7, **Predicted Survival**: 0\\n8. **PassengerId**: 8, **Predicted Survival**: 0\\n9. **PassengerId**: 9, **Predicted Survival**: 1\\n10. **PassengerId**: 10, **Predicted Survival**: 1\\n\\nIf you need further analysis or details, feel free to ask!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"用上一步训练好的模型进行预测，model_id为a313126e，返回前10条样例的预测结果。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
